
  
```{r setup, echo = FALSE, include = FALSE}
library("papaja")
library("knitr") # for knitting things
library("tidyverse") # for all things tidyverse
library("car")
library("lme4")
library("patchwork")
library("effsize")

# these options here change the formatting of how comments are rendered
opts_chunk$set(
  comment = "",
  results = "hold",
  fig.show = "hold")

# set the default ggplot theme 
theme_set(theme_classic())

r_refs("r-references.bib")
r_refs("references/packages.bib")

```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

```{r combine corpus and behavior data, include = F}
source("../2_combine/2_combine.R")
df.basefreq <- read.csv("../../data/corpus/basefreq_EMV.csv")

#no base frequencies for vietnamese yet
df.basefreq <- df.basefreq %>% select(triad, 
                                      cue_basefreq_E, tax_basefreq_E, theme_basefreq_E,
                                      cue_basefreq_M, tax_basefreq_M, theme_basefreq_M, 
                                      cue_basefreq_V, tax_basefreq_V, theme_basefreq_V)

df <- left_join(df, df.basefreq, by = "triad")
```

## Does cue given match  predict behavior better than match given cue?



## Do we extend previous work reporting a preference for taxonomic matching in the US and thematic matching in Asia?

```{r warning=FALSE, include=FALSE, paged.print=TRUE}
df.country <- df %>%
  group_by(subject, country) %>%
  summarize(theme_resp_percent = mean(responses_theme, na.rm = T))

df.country_sum <- df.country %>%
  group_by(country) %>%
  summarize(mean_theme_resp_percent = mean(theme_resp_percent), 
            sd_theme_resp_percent = sd(theme_resp_percent))

fit.country = glmer(responses_theme ~ country + (1 | subject) + (country | triad), 
                    data = df, 
                    family = "binomial")
summary(fit.country) 
fit.country.anova = Anova(fit.country, type=3)

fit.country_EN_VN = glmer(responses_theme ~ country + (1 | subject) + (country | triad), 
                    data = df %>% filter(country != "China"),
                    family = "binomial")
summary(fit.country_EN_VN) 
```
The group means of proportion of thematic response in mainland China is the highest (M = `r round((df.country_sum %>% filter(country == "China"))$mean_theme_resp_percent, 2)`, SD = `r round((df.country_sum %>% filter(country == "China"))$sd_theme_resp_percent, 2)`), followed by the groups means in Vietnam (M = `r round((df.country_sum %>% filter(country == "Vietnam"))$mean_theme_resp_percent, 2)`, SD = `r round((df.country_sum %>% filter(country == "Vietnam"))$sd_theme_resp_percent, 2)`), which is slightly higher than that of the US (M = `r round((df.country_sum %>% filter(country == "US"))$mean_theme_resp_percent, 2)`, SD = `r round((df.country_sum %>% filter(country == "US"))$sd_theme_resp_percent, 2)`).

```{r echo=FALSE, warning=FALSE, fig.cap="Proportion of thematic responses by country. Only US-China responding comparison shows a siginficant difference. We could not extend this to US-Vietnam responding comparison."}

#show violin plot
ggplot(df.country,
       mapping = aes(x = factor(country, levels=c("China", "US", "Vietnam")), 
                     y = theme_resp_percent, 
                     color = factor(country, levels=c("China", "US", "Vietnam")))) +
  geom_violin() +
  geom_jitter(height = 0, 
              alpha = 0.3) +  
  stat_summary(fun.data = "mean_cl_boot", 
               geom = "pointrange") + 
  labs(y = "Proportion Thematic Chosen", 
       x = "Country", 
       color = "Country") + 
  scale_color_manual(values=c("#D63230", "#1C77C3", "#F39237"))
```

```{r correlation of country response, echo=FALSE, warning=FALSE}
#US-China, US-Vietnam, China-Vietnam
df.triad_country <- df %>%
  group_by(triad, country) %>%
  summarize(emp_theme_prop = mean(responses_theme))

df.triad_country <- pivot_wider(data = df.triad_country, 
                                names_from = country, 
                                values_from = emp_theme_prop)
plotUSCN = ggplot(data = df.triad_country,
                  mapping = aes(x = US, 
                                y = China, 
                                label = triad)) +
   geom_text() + 
   geom_smooth(method = "lm") +
   labs(x = "Proportion Thematic Chosen (US)", 
        y = "Proportion Thematic Chosen (China)") + 
   xlim(0, 1) + 
   ylim(0, 1) + 
  theme(axis.title = element_text(size=rel(0.75)))

plotUSVN = ggplot(data = df.triad_country,
                  mapping = aes(x = US, 
                                y = Vietnam, 
                                label = triad)) +
   geom_text() + 
   geom_smooth(method = "lm") +
   labs(x = "Proportion Thematic Chosen (US)", 
        y = "Proportion Thematic Chosen (Vietnam)") + 
   xlim(0, 1) + 
   ylim(0, 1)  + 
  theme(axis.title = element_text(size=rel(0.75)))

plotCNVN = ggplot(data = df.triad_country,
                  mapping = aes(x = Vietnam,
                                y = China, 
                                label = triad)) +
   geom_text() + 
   geom_smooth(method = "lm") +
   labs(x = "Proportion Thematic Chosen (Vietnam)", 
        y = "Proportion Thematic Chosen (China)") + 
   xlim(0, 1) + 
   ylim(0, 1)  + 
  theme(axis.title = element_text(size=rel(0.75)))

corr.USCN = apa_print(cor.test(df.triad_country$US, 
                  df.triad_country$China, na.rm=T))

corr.USVN = apa_print(cor.test(df.triad_country$US, 
                  df.triad_country$Vietnam, na.rm=T))

corr.CNVN = apa_print(cor.test(df.triad_country$China, 
                  df.triad_country$Vietnam, na.rm=T))
```

```{r warning = F, fig.width = 8, fig.cap="Correlation between proportion thematic chosen by US-China participants, US-Vietnam participants, and China-Vietnam participants. All three comparisons show strong correlation, suggesting a strong signal of universality across cultural contexts regarding similarity judgments"}
plotUSCN + plotUSVN + plotCNVN +
  plot_layout(ncol = 3)
```

With a Pearson correlation test, we observed high correlations between thematic responding across all three countries. The proportion of US thematic responding is strongly correlated with thematic responding in China, `r corr.USCN$full_result`. The proportion of US thematic responding is strongly correlated with thematic responding in Vietnam, `r corr.USVN$full_result`. Likewise, the proportion of China thematic response is strongly correlated with thematic responding in Vietnam, `r corr.CNVN$full_result`. This points to a strong signal of universality across cultural contexts regarding similarity judgments.

```{r USCN effect size comparison, include=FALSE}
USCN_cohen <- cohen.d(df.triad_country$China, df.triad_country$US)
```

For comparison with previous work, we also included an effect size comparison for the difference in US-China thematic response data (though this was not a planned analysis). The effect size for this analysis was d = `r USCN_cohen$estimate`, a small effect size. This is smaller than the effect size from @Ji2004, even when we are unable to make a direct comparison. Calculating the effect size from the ANOVA reported in @Ji2004 between US participants tested in English and mainland China participants tested in English (both groups tested in the US) yields a Cohen's d = 0.81. @Ji2004 reported that mean thematic response for mainland China participants tested in Mandarin Chinese is higher than for those tested in English, so the effect size for a comparison between mainland China participants tested in Mandarin Chinese and US participants tested in English (parallel to our comparison) would likely have yielded an even larger effect size than 0.814. It is possible that we failed to replicate the magnitude of effect from @Ji2004 because the previous study calculated their dependent variable as frequency of thematic responses minus frequency of taxonomic responses, whereas our dependent variable is proportion of thematic response over total number of responses.

To test for cross-context differences in similarity judgments between the countries, we ran a mixed-effects logistic regression predicting triad responding (taxonomic or thematic) with country (US, China, or Vietnam) as a fixed effect. As random effects, we included an intercept per subject and one per triad, as well as by-triad random slopes for country to account for variation in the country effect across triads. In R syntax, the model is: response ~ country + (1 | subject) + (country | triad).

Overall, there is a significant effect of country on proportion of thematic responses ($\chi^2$(`r fit.country.anova["country", "Df"]`) = `r round(fit.country.anova["country", "Chisq"], 2)`, p < .001). However, this effect is driven by the difference between US and China responding ($\beta$ = `r round(fixef(fit.country)["countryUS"], 2)`, p < .001). There is no statistical difference between the Vietnam and China responding ($\beta$ = `r round(fixef(fit.country)["countryVietnam"], 2)`, p = `r round(as.data.frame(summary(fit.country)[["coefficients"]])["countryVietnam", "Pr(>|z|)"], 2)`), and the US and Vietnam responding ($\beta$ = `r round(fixef(fit.country_EN_VN)["countryVietnam"], 2)`, p = `r round(as.data.frame(summary(fit.country_EN_VN)[["coefficients"]])["countryVietnam", "Pr(>|z|)"], 3)`).

On this analysis, we do not find support that the US-China tendencies toward taxonomic and thematic responding (respectively) extend to the US-Vietnam comparison. Accordingly, we cannot speak to overall biases toward thematic responding across Asian cultural contexts broadly, but we do replicate the differences documented by @Ji2004 between the US and China. However, in our corpus model comparison, we do find evidence for different, more fine-grained variation in similarity judgments between the US and Vietnam. 

## Can the differences in similarity judgments between English, Mandarin and Vietnamese speakers be explained by variation in lexical statistics?
### Is responding in each cultural context predicted by the corresponding lexical statistics (raw co-occurrences and cosine distance)? 
```{r Pearson correlation between raw co-occurrences of corpora and responding, warning=FALSE, include=FALSE}

#raw co-occurrences
df.triad_country_freq <- df %>%
  filter(!(triad %in% triads_omit)) %>% # omit triads that do not have meaningful prediction (at least 1 non-zero prediction in both languages)
  group_by(triad, country, theme_freq_prop_E, theme_freq_prop_V, theme_freq_prop_M) %>%  # not working 
  summarize(emp_theme_prop = mean(responses_theme))
df.triad_country_freq   #sanity

df.triad_country_freq_E <- df.triad_country_freq %>%
  filter(country == "US")

#plotting English corpus against US responding data
plotE = ggplot(data = df.triad_country_freq_E,
        mapping = aes(x = emp_theme_prop,
                     y = theme_freq_prop_E,
                     label = triad)) +
   geom_text() +
   geom_smooth(method = "lm") +
   labs(x = "Proportion Thematic Chosen (US)",
        y = "Proportion Thematic Predicted (English)")
plotE

df.triad_country_freq_V <- df.triad_country_freq %>%
  filter(country == "Vietnam")

#plotting Vietnamese corpus against VN responding data
plotV = ggplot(data = df.triad_country_freq_V,
        mapping = aes(x = emp_theme_prop,
                     y = theme_freq_prop_V,
                     label = triad)) +
   geom_text() +
   geom_smooth(method = "lm") +
   labs(x = "Proportion Thematic Chosen (Vietnam)",
        y = "Proportion Thematic Predicted (Vietnamese)")
plotV

df.triad_country_freq_M <- df.triad_country_freq %>%
  filter(country == "China")

#plotting China corpus against CN responding data
plotM = ggplot(data = df.triad_country_freq_M,
        mapping = aes(x = emp_theme_prop,
                     y = theme_freq_prop_M,
                     label = triad)) +
   geom_text() +
   geom_smooth(method = "lm") +
   labs(x = "Proportion Thematic Chosen (China)",
        y = "Proportion Thematic Predicted (Chinese)")
plotM

#Pearson correlation between corpus and responding
corr.E = apa_print(cor.test(df.triad_country_freq_E$emp_theme_prop,
                  df.triad_country_freq_E$theme_freq_prop_E, na.rm=T))
corr.E

corr.V = apa_print(cor.test(df.triad_country_freq_V$emp_theme_prop,
                  df.triad_country_freq_V$theme_freq_prop_V, na.rm=T))
corr.V

corr.M = apa_print(cor.test(df.triad_country_freq_M$emp_theme_prop,
                  df.triad_country_freq_M$theme_freq_prop_M, na.rm=T))
corr.M

#Pearson correlation between EN and VI corpus
corr.EV = apa_print(cor.test(df.triad_country_freq_V$theme_freq_prop_V,
                   df.triad_country_freq_E$theme_freq_prop_E, na.rm=T))
corr.EM = apa_print(cor.test(df.triad_country_freq_M$theme_freq_prop_M,
                   df.triad_country_freq_E$theme_freq_prop_E, na.rm=T))
corr.MV = apa_print(cor.test(df.triad_country_freq_V$theme_freq_prop_V,
                   df.triad_country_freq_M$theme_freq_prop_M, na.rm=T))
```

```{r echo=FALSE, paged.print=FALSE, fig.cap ="Correlation between English corpus lexical co-occurrence and US responding, and Vietnamese corpus lexical co-occurrence and Vietnam responding."}
plotE + plotV + plotM
  plot_layout(ncol = 3)
```


We first conducted a Pearson correlation test between corresponding response data and corpus data. Looking at the raw lexical co-occurrence data, proportion of US thematic responding is moderately correlated to English corpus thematic proportion, `r corr.E$full_result`. Proportion of Vietnam thematic responding is moderately correlated to Vietnamese corpus thematic proportion, `r corr.V$full_result`. Proportion of China thematic responding is moderately correlated to Chinese corpus thematic proportion, `r corr.M$full_result`. 
There was a strong similarity signal between the thematic proportions in the English and Vietnamese corpora, `r corr.EV$full_result`, and the thematic proportions in the English and Mandarin corpora, `r corr.EM$full_result`. There was a moderate similarity signal between the proportions in the Mandarin and Vietnamese corpora, `r corr.MV$full_result.`

```{r Pearson correlation between corpus cosine distance and responding, warning=FALSE, include=FALSE}
df.triad_country_cos <- df %>%
  group_by(triad, country, theme_cosine_prop_E, theme_cosine_prop_V, theme_cosine_prop_M) %>%
  summarize(emp_theme_prop = mean(responses_theme))

df.triad_country_cos_E <- df.triad_country_cos %>%
  filter(country == "US")

plotE = ggplot(data = df.triad_country_cos_E, 
        mapping = aes(x = emp_theme_prop, 
                     y = theme_cosine_prop_E,
                     label = triad)) +
   geom_text() + 
   geom_smooth(method = "lm") +
   labs(x = "Proportion Thematic Chosen (US)", 
        y = "Proportion Thematic Predicted (English)") + 
   scale_y_reverse() + 
   xlim(0, 1) +
   ylim(0.8, 0.2) + 
  theme(axis.title = element_text(size=rel(0.75)))

df.triad_country_cos_V <- df.triad_country_cos %>%
  filter(country == "Vietnam")

plotV = ggplot(data = df.triad_country_cos_V, 
        mapping = aes(x = emp_theme_prop, 
                     y = theme_cosine_prop_V, 
                     label = triad)) +
   geom_text() + 
   geom_smooth(method = "lm") +
   labs(x = "Proportion Thematic Chosen (Vietnam)", 
        y = "Proportion Thematic Predicted (Vietnamese)") + 
   scale_y_reverse() +
   xlim(0, 1) +
   ylim(0.8, 0.2) + 
  theme(axis.title = element_text(size=rel(0.75)))

df.triad_country_cos_M <- df.triad_country_cos %>%
  filter(country == "China")

plotM = ggplot(data = df.triad_country_cos_M, 
        mapping = aes(x = emp_theme_prop, 
                     y = theme_cosine_prop_M, 
                     label = triad)) +
   geom_text() + 
   geom_smooth(method = "lm") +
   labs(x = "Proportion Thematic Chosen (China)", 
        y = "Proportion Thematic Predicted (Mandarin)") + 
   xlim(0, 1) +
   ylim(0.8, 0.2) + 
  theme(axis.title = element_text(size=rel(0.75)))
  
  
corr.E_cos = apa_print(cor.test(df.triad_country_cos_E$emp_theme_prop,
                      df.triad_country_cos_E$theme_cosine_prop_E, na.rm=T))

corr.V_cos = apa_print(cor.test(df.triad_country_cos_V$emp_theme_prop,
                      df.triad_country_cos_V$theme_cosine_prop_V, na.rm=T))

corr.M_cos = apa_print(cor.test(df.triad_country_cos_M$emp_theme_prop,
                      df.triad_country_cos_M$theme_cosine_prop_M, na.rm=T))

#correlation between corpora
corr.EV_cos = apa_print(cor.test(df.triad_country_cos_E$theme_cosine_prop_E,
                       df.triad_country_cos_V$theme_cosine_prop_V, na.rm=T))

corr.EM_cos = apa_print(cor.test(df.triad_country_cos_E$theme_cosine_prop_E,
                      df.triad_country_cos_M$theme_cosine_prop_M, na.rm=T))

corr.VM_cos = apa_print(cor.test(df.triad_country_cos_V$theme_cosine_prop_V,
                      df.triad_country_cos_M$theme_cosine_prop_M, na.rm=T))
```

```{r warning = FALSE, echo=FALSE, fig.width = 8, fig.cap="Correlation between English corpus cosine distance and US responding; Vietnamese corpus cosine distance and Vietnam responding; and Mandarin corpus cosine distance and China responding."}
#maybe we should include a note that explains why they are correlate in the opposite direction? 
#either changing the label of y-axis, or use y = 1/theme_cosine_prop_V? 
plotE + plotV + plotM +
  plot_layout(ncol = 3)
```

```{r US-Mandarin, China-English cross correlation, NOT SHOWN, eval=FALSE, warning=FALSE, include=FALSE}
plotUSZH = ggplot(data = df.triad_country_cos_E, 
        mapping = aes(x = emp_theme_prop, 
                     y = theme_cosine_prop_M,
                     label = triad)) +
   geom_text() + 
   geom_smooth(method = "lm") +
   labs(x = "Proportion Thematic Chosen (US)", 
        y = "Proportion Thematic Predicted (Mandarin)") + 
   scale_y_reverse() + 
   xlim(0, 1) +
   ylim(0.8, 0.3)


plotCNEN = ggplot(data = df.triad_country_cos_M, 
        mapping = aes(x = emp_theme_prop, 
                     y = theme_cosine_prop_E,
                     label = triad)) +
   geom_text() + 
   geom_smooth(method = "lm") +
   labs(x = "Proportion Thematic Chosen (China)", 
        y = "Proportion Thematic Predicted (English)") + 
   scale_y_reverse() + 
   xlim(0, 1) +
   ylim(0.8, 0.3)

plotUSZH + plotCNEN +
  plot_layout(ncol = 2)
```

Looking at the cosine distance data using fastText word vectors, proportion of US thematic responding is moderately correlated to English thematic cosine distance proportion, `r corr.E_cos$full_result`. There is a small correlation between proportion of Vietnam thematic responding and the Vietnamese thematic cosine distance proportion, `r corr.V_cos$full_result`. Proportion of China thematic responding is moderately correlated to Mandarin thematic match cosine distance proportion, `r corr.M_cos$full_result`. There were moderate signals of similarity between English and Mandarin (`r corr.EM_cos$full_result`). There was no significant correlation between English and Vietnamese (`r corr.EV_cos$full_result`), and between Vietnamese and Mandarin (`r corr.VM_cos$full_result`).

To test whether variation in lexical co-occurrence can explain differences in similarity judgments between US and Vietnam participants, we compare logistic mixed-effects regression models fit to the thematic responding data from each country separately. We first ask how well each corpus model (English, Vietnamese, or Mandarin) predicts similarity judgments by speakers of the corresponding language (US, Vietnam, or China). To do this, we use a mixed-effects logistic regression to predict triad responses (0=taxonomic or 1=thematic) with corpus prediction (proportion thematic co-occurrence or cosine distance) as a fixed effect and participant and triad as random effects.

#### Raw lexical co-occurrences

```{r US responding predicted by each corpus model raw co-occurrences, warning=FALSE, include=F}
# English 
fit.EN_US = glmer(responses_theme ~ theme_freq_prop_E + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "US", !(triad %in% triads_omit)), 
          family="binomial")
summary(fit.EN_US)
fit.EN_US.anova = Anova(fit.EN_US, type = 3)

#Vietnamese
fit.VI_US = glmer(responses_theme ~ theme_freq_prop_V + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "US", !(triad %in% triads_omit)), 
          family="binomial")
summary(fit.VI_US)
fit.VI_US.anova = Anova(fit.VI_US, type = 3)

#Mandarin
fit.ZH_US = glmer(responses_theme ~ theme_freq_prop_M + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "US", !(triad %in% triads_omit)), 
          family="binomial")
summary(fit.ZH_US)
fit.ZH_US.anova = Anova(fit.ZH_US, type = 3)
```

```{r VN responding predicted by each corpus model raw co-occurrences, warning=FALSE, include=F}
# English 
fit.EN_VN = glmer(responses_theme ~ theme_freq_prop_E + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "Vietnam", !(triad %in% triads_omit)), 
          family="binomial")
summary(fit.EN_VN)
fit.EN_VN.anova = Anova(fit.EN_VN, type = 3)

#Vietnamese
fit.VI_VN = glmer(responses_theme ~ theme_freq_prop_V + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "Vietnam", !(triad %in% triads_omit)), 
          family="binomial")
summary(fit.VI_VN)
fit.VI_VN.anova = Anova(fit.VI_VN, type = 3)

#Mandarin
fit.ZH_VN = glmer(responses_theme ~ theme_freq_prop_M + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "Vietnam", !(triad %in% triads_omit)), 
          family="binomial")
summary(fit.ZH_VN)
fit.ZH_VN.anova = Anova(fit.ZH_VN, type = 3)
```

```{r CN responding predicted by each corpus model raw co-occurrences, warning=FALSE, include=F}
#English
fit.EN_CN = glmer(responses_theme ~ theme_freq_prop_E + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "China", !(triad %in% triads_omit)), 
          family="binomial")
summary(fit.EN_CN)
fit.EN_CN.anova = Anova(fit.EN_CN, type = 3)

#Vietnamese
fit.VI_CN = glmer(responses_theme ~ theme_freq_prop_V + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "China", !(triad %in% triads_omit)), 
          family="binomial")
summary(fit.VI_CN)
fit.VI_CN.anova = Anova(fit.VI_CN, type = 3)

#Mandarin
fit.ZH_CN = glmer(responses_theme ~ theme_freq_prop_M + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "China", !(triad %in% triads_omit)), 
          family="binomial")
summary(fit.ZH_CN)
fit.ZH_CN.anova = Anova(fit.ZH_CN, type = 3)
```

TODO: ADD CHINA RESULTS
Both the English (EN) and Vietnamese (VI) corpus are significant predictors of US responding (EN-US model: $\beta$ = `r round(fixef(fit.EN_US)["theme_freq_prop_E"], 2)`, $\chi^2$(`r fit.EN_US.anova["theme_freq_prop_E", "Df"]`) = `r round(fit.EN_US.anova["theme_freq_prop_E", "Chisq"], 2)`, p < .001; VI-US model: $\beta$ = `r round(fixef(fit.VI_US)["theme_freq_prop_V"], 2)`, $\chi^2$(`r fit.VI_US.anova["theme_freq_prop_V", "Df"]`) = `r round(fit.VI_US.anova["theme_freq_prop_V", "Chisq"], 2)`, p < .001). 

Similarly, both the English (EN) and Vietnamese (VI) corpus are significant predictors of Vietnam (VN) responding (EN-VN model: $\beta$ = `r round(fixef(fit.EN_VN)["theme_freq_prop_E"], 2)`, $\chi^2$(`r fit.EN_VN.anova["theme_freq_prop_E", "Df"]`) = `r round(fit.EN_VN.anova["theme_freq_prop_E", "Chisq"], 2)`, p < .001; VI-VN model: $\beta$ = `r round(fixef(fit.VI_VN)["theme_freq_prop_V"], 2)`, $\chi^2$(`r fit.VI_VN.anova["theme_freq_prop_V", "Df"]`) = `r round(fit.VI_VN.anova["theme_freq_prop_V", "Chisq"], 2)`, p < .001). 

This suggests a strong shared similarity signal across the languages, which is also reflected in the strong correlation between the two corpus models reported above (`r corr.EV$full_result`).

#### Cosine distances of fastText word vectors
```{r US responding predicted by each corpus model cosine differences, warning=FALSE, include=F}
#English
fit.EN_US_cos = glmer(responses_theme ~ theme_cosine_prop_E + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "US"), 
          family="binomial")
summary(fit.EN_US_cos)
fit.EN_US_cos.anova = Anova(fit.EN_US_cos, type = 3)
fit.EN_US_cos.anova

#Vietnamese
fit.VI_US_cos = glmer(responses_theme ~ theme_cosine_prop_V + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "US"), 
          family="binomial")
summary(fit.VI_US_cos)
fit.VI_US_cos.anova = Anova(fit.VI_US_cos, type = 3)
fit.VI_US_cos.anova

#Mandarin
fit.ZH_US_cos = glmer(responses_theme ~ theme_cosine_prop_M + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "US"), 
          family="binomial")
summary(fit.ZH_US_cos)
fit.ZH_US_cos.anova = Anova(fit.ZH_US_cos, type = 3)
fit.ZH_US_cos.anova
```

```{r VN responding predicted by each corpus model cosine differences, warning=FALSE, include=F}
#English
fit.EN_VN_cos = glmer(responses_theme ~ theme_cosine_prop_E + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "Vietnam"), 
          family="binomial")
summary(fit.EN_VN_cos)
fit.EN_VN_cos.anova = Anova(fit.EN_VN_cos, type = 3)
fit.EN_VN_cos.anova

#Vietnamese
fit.VI_VN_cos = glmer(responses_theme ~ theme_cosine_prop_V + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "Vietnam"), 
          family="binomial")
summary(fit.VI_VN_cos)
fit.VI_VN_cos.anova = Anova(fit.VI_VN_cos, type = 3)
fit.VI_VN_cos.anova

#Mandarin
fit.ZH_VN_cos = glmer(responses_theme ~ theme_cosine_prop_M + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "Vietnam"), 
          family="binomial")
summary(fit.ZH_VN_cos)
fit.ZH_VN_cos.anova = Anova(fit.ZH_VN_cos, type = 3)
fit.ZH_VN_cos.anova
```

```{r CN responding predicted by each corpus model cosine differences, warning=FALSE, include=F}
## English
fit.EN_CN_cos = glmer(responses_theme ~ theme_cosine_prop_E + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "China"), 
          family="binomial")
summary(fit.EN_CN_cos)
fit.EN_CN_cos.anova = Anova(fit.EN_CN_cos, type = 3)
fit.EN_CN_cos.anova

#Vietnamese
fit.VI_CN_cos = glmer(responses_theme ~ theme_cosine_prop_V + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "China"), 
          family="binomial")
summary(fit.VI_CN_cos)
fit.VI_CN_cos.anova = Anova(fit.VI_CN_cos, type = 3)
fit.VI_CN_cos.anova

#Mandarin
fit.ZH_CN_cos = glmer(responses_theme ~ theme_cosine_prop_M + (1 | subject) + (1 | triad), 
          data = df %>% filter(country == "China"), 
          family="binomial")
summary(fit.ZH_CN_cos)
fit.ZH_CN_cos.anova = Anova(fit.ZH_CN_cos, type = 3)
fit.ZH_CN_cos.anova
```

Similar to the results from the analysis with raw lexical co-occurrences, we found that all corpora are significant predictors of all cultural context responding. 

For US responding: English (EN), Vietnamese (VI), and Mandarin (ZH) corpus are significant predictors of US responding (EN-US model: $\beta$ = `r round(fixef(fit.EN_US_cos)["theme_cosine_prop_E"], 2)`, $\chi^2$(`r fit.EN_US_cos.anova["theme_cosine_prop_E", "Df"]`) = `r round(fit.EN_US_cos.anova["theme_cosine_prop_E", "Chisq"], 2)`, p < .001; VI-US model: $\beta$ = `r round(fixef(fit.VI_US_cos)["theme_cosine_prop_V"], 2)`, $\chi^2$(`r fit.VI_US_cos.anova["theme_cosine_prop_V", "Df"]`) = `r round(fit.VI_US_cos.anova["theme_cosine_prop_V", "Chisq"], 2)`, p = `r round(fit.VI_US_cos.anova["theme_cosine_prop_V", "Pr(>Chisq)"], 3)`; ZH-US model: $\beta$ = `r round(fixef(fit.ZH_US_cos)["theme_cosine_prop_M"], 2)`, $\chi^2$(`r fit.ZH_US_cos.anova["theme_cosine_prop_M", "Df"]`) = `r round(fit.ZH_US_cos.anova["theme_cosine_prop_M", "Chisq"], 2)`, p < .001). 

For Vietnam (VN) responding: English (EN), Vietnamese (VI), and Mandarin (ZH) corpus are significant predictors of VN responding (EN-VN model: $\beta$ = `r round(fixef(fit.EN_VN_cos)["theme_cosine_prop_E"], 2)`, $\chi^2$(`r fit.EN_VN_cos.anova["theme_cosine_prop_E", "Df"]`) = `r round(fit.EN_VN_cos.anova["theme_cosine_prop_E", "Chisq"], 2)`, p < .001; VI-VN model: $\beta$ = `r round(fixef(fit.VI_VN_cos)["theme_cosine_prop_V"], 2)`, $\chi^2$(`r fit.VI_VN_cos.anova["theme_cosine_prop_V", "Df"]`) = `r round(fit.VI_VN_cos.anova["theme_cosine_prop_V", "Chisq"], 2)`, p = `r round(fit.VI_VN_cos.anova["theme_cosine_prop_V", "Pr(>Chisq)"], 3)`; ZH-VN model: $\beta$ = `r round(fixef(fit.ZH_VN_cos)["theme_cosine_prop_M"], 2)`, $\chi^2$(`r fit.ZH_VN_cos.anova["theme_cosine_prop_M", "Df"]`) = `r round(fit.ZH_VN_cos.anova["theme_cosine_prop_M", "Chisq"], 2)`, p < .001). 

For China (CN) responding: English (EN), Vietnamese (VI), and Mandarin (ZH) corpus are significant predictors of CN responding (EN-CN model: $\beta$ = `r round(fixef(fit.EN_CN_cos)["theme_cosine_prop_E"], 2)`, $\chi^2$(`r fit.EN_CN_cos.anova["theme_cosine_prop_E", "Df"]`) = `r round(fit.EN_CN_cos.anova["theme_cosine_prop_E", "Chisq"], 2)`, p < .001; VI-CN model: $\beta$ = `r round(fixef(fit.VI_CN_cos)["theme_cosine_prop_V"], 2)`, $\chi^2$(`r fit.VI_CN_cos.anova["theme_cosine_prop_V", "Df"]`) = `r round(fit.VI_CN_cos.anova["theme_cosine_prop_V", "Chisq"], 2)`, p = `r round(fit.VI_VN_cos.anova["theme_cosine_prop_V", "Pr(>Chisq)"], 3)`; ZH-CN model: $\beta$ = `r round(fixef(fit.ZH_CN_cos)["theme_cosine_prop_M"], 2)`, $\chi^2$(`r fit.ZH_CN_cos.anova["theme_cosine_prop_M", "Df"]`) = `r round(fit.ZH_CN_cos.anova["theme_cosine_prop_M", "Chisq"], 2)`, p < .001). 

### Is responding in each cultural context __best__ predicted by the corresponding corpus's lexical statistics (raw co-occurrences and cosine distance), as opposed to the other two corpora?
Next, we directly compare the corpus models by including both as fixed effects in two mixed-effect regressions (predicting US and Vietnam responding) with the same random effects as above. In R syntax, the model is: response ~ corpus_English + corpus_Vietnamese + corpus_Mandarin + (1|triad) + (1|subject). 

#### Raw co-occurrences 
```{r MIGHT NEED TO REMOVEEnglish + Vietnamese raw co-occurrences predicting US and Vietnam, warning=FALSE, include=F}
## English/Vietnamese comparison
fit.ENVI_US = glmer(responses_theme ~ theme_freq_prop_E + theme_freq_prop_V + 
                      (1 | subject) + (1 | triad), 
                    data = df %>% filter(country == "US"), 
                    family="binomial")
summary(fit.ENVI_US)
fit.ENVI_US.anova = Anova(fit.ENVI_US, type = 3)
fit.ENVI_US.anova

fit.ENVI_VN = glmer(responses_theme ~ theme_freq_prop_V + theme_freq_prop_E + 
                      (1 | subject) + (1 | triad), 
                    data = df %>% filter(country == "Vietnam"), 
                    family="binomial")
summary(fit.ENVI_VN)
fit.ENVI_VN.anova = Anova(fit.ENVI_VN, type = 3)
fit.ENVI_VN.anova
```
When we included both corpora as predictors for US responding, only the English corpus has a significant effect ($\beta$ = `r round(fixef(fit.ENVI_US)["theme_freq_prop_E"], 2)`, $\chi^2$(`r fit.ENVI_US.anova["theme_freq_prop_E", "Df"]`) = `r round(fit.ENVI_US.anova["theme_freq_prop_E", "Chisq"], 2)`, p < .001). There is no effect of the Vietnamese corpus ($\beta$ = `r round(fixef(fit.ENVI_US)["theme_freq_prop_V"], 2)`, $\chi^2$(`r fit.ENVI_US.anova["theme_freq_prop_V", "Df"]`) = `r round(fit.ENVI_US.anova["theme_freq_prop_V", "Chisq"], 2)`, p = `r round(fit.ENVI_US.anova["theme_freq_prop_V", "Pr(>Chisq)"], 3)`). 

However, when both corpora are included as predictors for Vietnam responding -- both corpora has a significant effect (English corpus: $\beta$ = `r round(fixef(fit.ENVI_VN)["theme_freq_prop_E"], 2)`, $\chi^2$(`r fit.ENVI_VN.anova["theme_freq_prop_E", "Df"]`) = `r round(fit.ENVI_VN.anova["theme_freq_prop_E", "Chisq"], 2)`, p = `r round(fit.ENVI_VN.anova["theme_freq_prop_E", "Pr(>Chisq)"], 3)`; Vietnamese corpus: $\beta$ = `r round(fixef(fit.ENVI_VN)["theme_freq_prop_V"], 2)`, $\chi^2$(`r fit.ENVI_VN.anova["theme_freq_prop_V", "Df"]`) = `r round(fit.ENVI_VN.anova["theme_freq_prop_V", "Chisq"], 2)`, p = `r round(fit.ENVI_VN.anova["theme_freq_prop_V", "Pr(>Chisq)"], 3)`).

```{r Eng-Vie-Mand lexical co-occ predicting US, VN, CN, warning=FALSE, include=F}
# ADDITION: adding theme_freq_prop_M
#raw co-occurrences
#linear mixed model with ALL corpora as predictors for each population.
fit.ENVIZH_US = glmer(responses_theme ~ 
                      theme_freq_prop_E + theme_freq_prop_V + theme_freq_prop_M +
                      (1 | subject) + (1 | triad), 
                    data = df %>% filter(country == "US", !(triad %in% triads_omit)),
                    family="binomial")
summary(fit.ENVIZH_US)
fit.ENVIZH_US.anova = Anova(fit.ENVIZH_US, type = 3)
fit.ENVIZH_US.anova

fit.ENVIZH_VN = glmer(responses_theme ~ 
                      theme_freq_prop_V + theme_freq_prop_E + theme_freq_prop_M +
                      (1 | subject) + (1 | triad), 
                    data = df %>% filter(country == "Vietnam", !(triad %in% triads_omit)),
                    family="binomial")
summary(fit.ENVIZH_VN)
fit.ENVIZH_VN.anova = Anova(fit.ENVIZH_VN, type = 3)
fit.ENVIZH_VN.anova

fit.ENVIZH_CN = glmer(responses_theme ~ 
                      theme_freq_prop_V + theme_freq_prop_E + theme_freq_prop_M +
                      (1 | subject) + (1 | triad), 
                    data = df %>% filter(country == "China", !(triad %in% triads_omit)),
                    family="binomial")
summary(fit.ENVIZH_CN)
fit.ENVIZH_CN.anova = Anova(fit.ENVIZH_CN, type = 3)
fit.ENVIZH_CN.anova
```
TODO: ADD WRITE-UP OF RESULTS

```{r echo=FALSE, warning = FALSE, fig.cap = "Fixed effect sizes of each corpus when included as a predictor for China, US, and Vietnam responding, respectively. The English corpus is the best predictor for US response, and the Mandarin corpus is the best predictor for China response."}
coeff_value_freq <- c(fixef(fit.ENVIZH_US)["theme_freq_prop_E"],
                 fixef(fit.ENVIZH_US)["theme_freq_prop_V"], 
                 fixef(fit.ENVIZH_US)["theme_freq_prop_M"],
                 fixef(fit.ENVIZH_VN)["theme_freq_prop_E"],
                 fixef(fit.ENVIZH_VN)["theme_freq_prop_V"],
                 fixef(fit.ENVIZH_VN)["theme_freq_prop_M"], 
                 fixef(fit.ENVIZH_CN)["theme_freq_prop_E"],
                 fixef(fit.ENVIZH_CN)["theme_freq_prop_V"], 
                 fixef(fit.ENVIZH_CN)["theme_freq_prop_M"])

se_value_freq <- c(summary(fit.ENVIZH_US)$coef["theme_freq_prop_E", "Std. Error"], 
              summary(fit.ENVIZH_US)$coef["theme_freq_prop_V", "Std. Error"],
              summary(fit.ENVIZH_US)$coef["theme_freq_prop_M", "Std. Error"], 
              summary(fit.ENVIZH_VN)$coef["theme_freq_prop_E", "Std. Error"], 
              summary(fit.ENVIZH_VN)$coef["theme_freq_prop_V", "Std. Error"],
              summary(fit.ENVIZH_VN)$coef["theme_freq_prop_M", "Std. Error"],
              summary(fit.ENVIZH_CN)$coef["theme_freq_prop_E", "Std. Error"], 
              summary(fit.ENVIZH_CN)$coef["theme_freq_prop_V", "Std. Error"],
              summary(fit.ENVIZH_CN)$coef["theme_freq_prop_M", "Std. Error"])

country_value <- c(rep("US", 3),
                   rep("VN", 3),
                   rep("CN", 3))

corpus_value <- c(rep(c("EN", "VI", "ZH"), 3))

df.USVNCN_coeffs_freq <- data.frame(country_value, corpus_value, coeff_value_freq, se_value_freq)

ggplot(data = df.USVNCN_coeffs_freq, 
       mapping = aes(x = country_value, y = coeff_value_freq, fill = corpus_value)) +
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(aes(ymin= coeff_value_freq - se_value_freq, ymax = coeff_value_freq + se_value_freq), width=.2,
                 position=position_dodge(.9)) +
  scale_y_reverse() + 
  labs(x = "Country", y = "Fixed effect size", fill = "Corpus") + 
  scale_x_discrete(labels=c("CN" = "China", "US" = "US", "VN" = "Vietnam")) + 
  scale_fill_manual(values=c("#D63230", "#1C77C3", "#F39237"))
  
```

```{r model comparison, include=FALSE}
fit.US_freq_compare = anova(fit.ENVIZH_US, fit.EN_US, type = 3)
fit.VN_freq_compare = anova(fit.ENVIZH_VN, fit.VI_VN, type = 3)
fit.CN_freq_compare = anova(fit.ENVIZH_CN, fit.ZH_CN, type = 3)
```

TODO: ADD WRITE-UP ON RESULTS 

#### Cosine distances of fastText word vectors

```{r Eng-Vie-Mand cosine similarities predicting US, VN, CN warning=FALSE, include=FALSE}
## English/Vietnamese/Mandarin comparison
fit.ENVIZH_US_cos = glmer(responses_theme ~ theme_cosine_prop_E + theme_cosine_prop_V + theme_cosine_prop_M +
                      (1 | subject) + (1 | triad), 
                    data = df %>% filter(country == "US"), 
                    family="binomial")
summary(fit.ENVIZH_US_cos)
fit.ENVIZH_US_cos.anova = Anova(fit.ENVIZH_US_cos, type = 3)
fit.ENVIZH_US_cos.anova

fit.ENVIZH_VN_cos = glmer(responses_theme ~ theme_cosine_prop_V + theme_cosine_prop_E + theme_cosine_prop_M +
                      (1 | subject) + (1 | triad), 
                    data = df %>% filter(country == "Vietnam"), 
                    family="binomial")
summary(fit.ENVIZH_VN_cos)
fit.ENVIZH_VN_cos.anova = Anova(fit.ENVIZH_VN_cos, type = 3)
fit.ENVIZH_VN_cos.anova

fit.ENVIZH_CN_cos = glmer(responses_theme ~ theme_cosine_prop_M + theme_cosine_prop_E + theme_cosine_prop_V +
                      (1 | subject) + (1 | triad), 
                    data = df %>% filter(country == "China"), 
                    family="binomial")
summary(fit.ENVIZH_CN_cos)
fit.ENVIZH_CN_cos.anova = Anova(fit.ENVIZH_CN_cos, type = 3)
fit.ENVIZH_CN_cos.anova
```

When we included all corpora thematic cosine distance proportion as predictors, all corpora are significant in predicting all cultural context's responding. 

For US responding: English (EN), Vietnamese (VI), and Mandarin (ZH) corpus are all significant predictors. EN corpus: $\beta$ = `r round(fixef(fit.ENVIZH_US_cos)["theme_cosine_prop_E"], 2)`, $\chi^2$(`r fit.ENVIZH_US_cos.anova["theme_cosine_prop_E", "Df"]`) = `r round(fit.ENVIZH_US_cos.anova["theme_cosine_prop_E", "Chisq"], 2)`, p < .001. VI corpus: $\beta$ = `r round(fixef(fit.ENVIZH_US_cos)["theme_cosine_prop_V"], 2)`, $\chi^2$(`r fit.ENVIZH_US_cos.anova["theme_cosine_prop_V", "Df"]`) = `r round(fit.ENVIZH_US_cos.anova["theme_cosine_prop_V", "Chisq"], 2)`, p = `r round(fit.ENVIZH_US_cos.anova["theme_cosine_prop_V", "Pr(>Chisq)"], 3)`. ZH corpus: $\beta$ = `r round(fixef(fit.ENVIZH_US_cos)["theme_cosine_prop_M"], 2)`, $\chi^2$(`r fit.ENVIZH_US_cos.anova["theme_cosine_prop_M", "Df"]`) = `r round(fit.ENVIZH_US_cos.anova["theme_cosine_prop_M", "Chisq"], 2)`, p = `r round(fit.ENVIZH_US_cos.anova["theme_cosine_prop_M", "Pr(>Chisq)"], 3)`.

For Vietnam responding: English (EN), Vietnamese (VI), and Mandarin (ZH) corpus are all significant predictors. EN corpus: $\beta$ = `r round(fixef(fit.ENVIZH_VN_cos)["theme_cosine_prop_E"], 2)`, $\chi^2$(`r fit.ENVIZH_VN_cos.anova["theme_cosine_prop_E", "Df"]`) = `r round(fit.ENVIZH_VN_cos.anova["theme_cosine_prop_E", "Chisq"], 2)`, p = `r round(fit.ENVIZH_VN_cos.anova["theme_cosine_prop_E", "Pr(>Chisq)"], 3)`. VI corpus: $\beta$ = `r round(fixef(fit.ENVIZH_VN_cos)["theme_cosine_prop_V"], 2)`, $\chi^2$(`r fit.ENVIZH_VN_cos.anova["theme_cosine_prop_V", "Df"]`) = `r round(fit.ENVIZH_VN_cos.anova["theme_cosine_prop_V", "Chisq"], 2)`, p = `r round(fit.ENVIZH_VN_cos.anova["theme_cosine_prop_V", "Pr(>Chisq)"], 3)`. ZH corpus: $\beta$ = `r round(fixef(fit.ENVIZH_VN_cos)["theme_cosine_prop_M"], 2)`, $\chi^2$(`r fit.ENVIZH_VN_cos.anova["theme_cosine_prop_M", "Df"]`) = `r round(fit.ENVIZH_VN_cos.anova["theme_cosine_prop_M", "Chisq"], 2)`, p = `r round(fit.ENVIZH_VN_cos.anova["theme_cosine_prop_M", "Pr(>Chisq)"], 3)`.

For China responding: English (EN), Vietnamese (VI), and Mandarin (ZH) corpus are all significant predictors. EN corpus: $\beta$ = `r round(fixef(fit.ENVIZH_CN_cos)["theme_cosine_prop_E"], 2)`, $\chi^2$(`r fit.ENVIZH_CN_cos.anova["theme_cosine_prop_E", "Df"]`) = `r round(fit.ENVIZH_CN_cos.anova["theme_cosine_prop_E", "Chisq"], 2)`, p = `r round(fit.ENVIZH_CN_cos.anova["theme_cosine_prop_E", "Pr(>Chisq)"], 3)`. VI corpus: $\beta$ = `r round(fixef(fit.ENVIZH_CN_cos)["theme_cosine_prop_V"], 2)`, $\chi^2$(`r fit.ENVIZH_CN_cos.anova["theme_cosine_prop_V", "Df"]`) = `r round(fit.ENVIZH_CN_cos.anova["theme_cosine_prop_V", "Chisq"], 2)`, p = `r round(fit.ENVIZH_CN_cos.anova["theme_cosine_prop_V", "Pr(>Chisq)"], 3)`. ZH corpus: $\beta$ = `r round(fixef(fit.ENVIZH_CN_cos)["theme_cosine_prop_M"], 2)`, $\chi^2$(`r fit.ENVIZH_CN_cos.anova["theme_cosine_prop_M", "Df"]`) = `r round(fit.ENVIZH_CN_cos.anova["theme_cosine_prop_M", "Chisq"], 2)`, p = < .001.

We observed some level of language specificity from this analysis. The English corpus is the best predictor for US responding, and the Mandarin corpus is the best predictor for China response. While this is not the case with the Vietnamese corpus and the Vietnam responding, the Vietnamese corpus is still a significant predictor for the Vietnam responding. 

```{r echo=FALSE, warning = FALSE, fig.cap = "Fixed effect sizes of each corpus when included as a predictor for China, US, and Vietnam responding, respectively. The English corpus is the best predictor for US response, and the Mandarin corpus is the best predictor for China response."}
coeff_value_cos <- c(fixef(fit.ENVIZH_US_cos)["theme_cosine_prop_E"],
                 fixef(fit.ENVIZH_US_cos)["theme_cosine_prop_V"], 
                 fixef(fit.ENVIZH_US_cos)["theme_cosine_prop_M"],
                 fixef(fit.ENVIZH_VN_cos)["theme_cosine_prop_E"],
                 fixef(fit.ENVIZH_VN_cos)["theme_cosine_prop_V"],
                 fixef(fit.ENVIZH_VN_cos)["theme_cosine_prop_M"], 
                 fixef(fit.ENVIZH_CN_cos)["theme_cosine_prop_E"],
                 fixef(fit.ENVIZH_CN_cos)["theme_cosine_prop_V"], 
                 fixef(fit.ENVIZH_CN_cos)["theme_cosine_prop_M"])

se_value_cos <- c(summary(fit.ENVIZH_US_cos)$coef["theme_cosine_prop_E", "Std. Error"], 
              summary(fit.ENVIZH_US_cos)$coef["theme_cosine_prop_V", "Std. Error"],
              summary(fit.ENVIZH_US_cos)$coef["theme_cosine_prop_M", "Std. Error"], 
              summary(fit.ENVIZH_VN_cos)$coef["theme_cosine_prop_E", "Std. Error"], 
              summary(fit.ENVIZH_VN_cos)$coef["theme_cosine_prop_V", "Std. Error"],
              summary(fit.ENVIZH_VN_cos)$coef["theme_cosine_prop_M", "Std. Error"],
              summary(fit.ENVIZH_CN_cos)$coef["theme_cosine_prop_E", "Std. Error"], 
              summary(fit.ENVIZH_CN_cos)$coef["theme_cosine_prop_V", "Std. Error"],
              summary(fit.ENVIZH_CN_cos)$coef["theme_cosine_prop_M", "Std. Error"])

country_value <- c(rep("US", 3),
                   rep("VN", 3),
                   rep("CN", 3))

corpus_value <- c(rep(c("EN", "VI", "ZH"), 3))

df.USVNCN_coeffs_cos <- data.frame(country_value, corpus_value, coeff_value_cos, se_value_cos)

ggplot(data = df.USVNCN_coeffs_cos, 
       mapping = aes(x = country_value, y = coeff_value_cos, fill = corpus_value)) +
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(aes(ymin= coeff_value_cos - se_value_cos, ymax = coeff_value_cos + se_value_cos), width=.2,
                 position=position_dodge(.9)) +
  scale_y_reverse() + 
  labs(x = "Country", y = "Fixed effect size", fill = "Corpus") + 
  scale_x_discrete(labels=c("CN" = "China", "US" = "US", "VN" = "Vietnam")) + 
  scale_fill_manual(values=c("#D63230", "#1C77C3", "#F39237"))
  
```

```{r model comparison, include=FALSE}
fit.US_cos_compare = anova(fit.ENVIZH_US_cos, fit.EN_US_cos, type = 3)
fit.VN_cos_compare = anova(fit.ENVIZH_VN_cos, fit.VI_VN_cos, type = 3)
fit.CN_cos_compare = anova(fit.ENVIZH_CN_cos, fit.ZH_CN_cos, type = 3)
```

However, we found that language specificity alone does not explain our results. We used an ANOVA to compare the model with only the corresponding corpus, and the model with all 3 corpora for each cultural context. We found that in all three cases (US, China, Vietnam), adding the other two corpora produces a significantly better fit than the identical model without the additional corpora, and only the corresponding corpus included as a predictor (US response: $\chi^2$(`r fit.US_compare["fit.ENVIZH_US_cos", "Df"]`) = `r round(fit.US_compare["fit.ENVIZH_US_cos", "Chisq"], 2)`, p = `r round(fit.US_compare["fit.ENVIZH_US_cos", "Pr(>Chisq)"], 3)`; Vietnam response: $\chi^2$(`r fit.VN_compare["fit.ENVIZH_VN_cos", "Df"]`) = `r round(fit.VN_compare["fit.ENVIZH_VN_cos", "Chisq"], 2)`, p = < .001; China response: $\chi^2$(`r fit.CN_compare["fit.ENVIZH_CN_cos", "Df"]`) = `r round(fit.CN_compare["fit.ENVIZH_CN_cos", "Chisq"], 2)`, p = `r round(fit.CN_compare["fit.ENVIZH_CN_cos", "Pr(>Chisq)"], 3)`). 

```{r add linguistic model to Ji et al., include=FALSE}
fit.country = glmer(responses_theme ~ country + (1 | subject) + (1 | triad), 
                           data = df %>% filter(country != "Vietnam"), 
                           family = "binomial")

fit.country_corpus = glmer(responses_theme ~ country + theme_cosine_prop_E + theme_cosine_prop_M + (1 | subject) + (1 | triad), 
                           data = df %>% filter(country != "Vietnam"), 
                           family = "binomial")

fit.add_corpus <- anova(fit.country, fit.country_corpus, type = 3)
                   
```

We carried out an ANOVA model comparison to compare our approach with previous studies that did not include corpus information. Because @Ji2004 only compared US and China participants, we filtered our data to only include responding data from these two countries. Our approach would be to compare a model that only includes country (US or China) as a fixed effect with one that also includes English and Chinese corpus data. Our previous model with an intercept per subject and one per triad, as well as by-triad random slopes for country to account for variation in the country effect across triads fails to converge with the more complex model, so we include a simpler random effect structure with an intercept per subject and one per triad in both the basic and more complex model. We compare this model with an identical model but including Chinese and English corpus cosine distance proportion prediction. We found that adding English and Chinese corpus data produces a significantly better fit than the identical model without English and Chinese corpus data as predictors ($\chi^2$(`r fit.add_corpus["fit.country_corpus", "Df"]`) = `r round(fit.add_corpus["fit.country_corpus", "Chisq"], 2)`, p = < .001. This suggests that including corpus data would better model the cross-cultural differences in similarity judgment in this study as well as similar studies.


## Exploratory analysis 

Because our exclusion criterion for attention checks excluded over 50% Vietnam participants, we carried out exploratory analysis where we applied less stringent exclusion criteria. In the following analysis, we only exclude participants who miss more than 2 attention checks (rather than any attention checks). We kept the rest of the exclusion criteria. 

TODO: CREATE .CSV FILES FOR THESE, SEPARATE OUT R SCRIPT INTO RMD.
```{r loading data E explore, warning=FALSE, include=F}
df.resp_E <- read.csv("../../data/data_E_0319.csv") %>%
  select(-X)

# check for participants who completed the entire experiment. Because the experiment is
# quite long, some participants decide to come back afterwards, so there are a few files
# that are recorded as incomplete. 
df.ppts_finished_E <- df.resp_E %>% 
  group_by(subject) %>%
  summarize(finished = ifelse("demo-final" %in% unique(variable_type), "yes", "no")) %>%
  filter(finished == "yes")

df.resp_E <- df.resp_E %>%
  filter(subject %in% df.ppts_finished_E$subject) 

df.ppts_att_E <- df.resp_E %>%
  filter(stim_type == "attention check") %>%
  mutate(correct_response = strsplit(cue, "Choose ")) %>%
  mutate(correct_response = sapply(correct_response, "[[", 2)) %>%
  mutate(pass_att_check = ifelse(responses == correct_response, 1, 0)) %>%
  group_by(subject) %>%
  summarize(pass_att_check_percent = mean(pass_att_check)) %>%
  filter(pass_att_check_percent >= 0.8)

df.resp_E <- df.resp_E %>%
  filter(subject %in% df.ppts_att_E$subject) 
```

```{r exclusion E explore, include = F, warning = F}
#non-native speaker
split_responses_demog <- function(responses) {
  responses <- as.character(responses)
  response_list <- unlist(strsplit(responses, ',|:'))
  response_list <- response_list[seq(1, length(response_list))]
  response_list <- gsub("}", "", response_list)
  response_list <- gsub("\"", "", response_list)
  return(response_list)
}

NATIVE_LANG = 2
get_native_lang <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  if(responses[NATIVE_LANG-1] != "{firstlanguage") 
    {warnings("cannot find native language answer")}
  else
    {return (responses[NATIVE_LANG])}
})

df.ppts_non_native_lang_E <- df.resp_E %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_language") %>%
  mutate(native_speaker = get_native_lang(responses)) %>%
  filter(native_speaker == "No")

ppts_non_native_lang_E = unique(df.ppts_non_native_lang_E$subject)#18
percent_dropped = length(ppts_non_native_lang_E) / length(unique(df.resp_E$subject))
percent_dropped #0.1041667

#fluent in Vietnamese & Mandarin
SPEAKER = 2
SPEAKING = 23
UNDERSTANDING = 46

get_speaker <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[SPEAKER])
})

get_fluency_speaking <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[SPEAKING])
})

get_fluency_understanding <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[UNDERSTANDING])
})

df.lang_vi_E <- df.resp_E %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_language_vi") %>%
  mutate(vi_speaker = get_speaker(responses))
  
df.lang_vi_fluency_E <- df.resp_E %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_conditional_language_vn_fluency") %>%
  mutate(vi_fluency_sp = as.numeric(get_fluency_speaking(responses))) %>%
  mutate(vi_fluency_ud = as.numeric(get_fluency_understanding(responses)))

df.lang_vi_E <- full_join(df.lang_vi_E, 
                          df.lang_vi_fluency_E, 
                          by = "subject") %>%
  select(subject, vi_speaker, vi_fluency_sp, vi_fluency_ud) %>%
  filter(vi_speaker == "Yes",
         vi_fluency_sp > 4, 
         vi_fluency_ud > 4)

ppts_vi_speaker_E = unique(df.lang_vi_E$subject) #4
percent_dropped = length(ppts_vi_speaker_E) / length(unique(df.resp_E$subject))
percent_dropped #0.02083333

df.lang_zh_E <- df.resp_E %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_language_cn") %>%
  mutate(zh_speaker = get_speaker(responses))
  
df.lang_zh_fluency_E <- df.resp_E %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_conditional_language_cn_fluency") %>%
  mutate(zh_fluency_sp = as.numeric(get_fluency_speaking(responses))) %>%
  mutate(zh_fluency_ud = as.numeric(get_fluency_understanding(responses)))

df.lang_zh_E <- full_join(df.lang_zh_E, 
                          df.lang_zh_fluency_E, 
                          by = "subject") %>%
  select(subject, zh_speaker, zh_fluency_sp, zh_fluency_ud) %>%
  filter(zh_speaker == "Yes",
         zh_fluency_sp > 4, 
         zh_fluency_ud > 4)

ppts_zh_speaker_E = unique(df.lang_zh_E$subject) #30
percent_dropped = length(ppts_zh_speaker_E) / length(unique(df.resp_E$subject))
percent_dropped #0.1822917

#have lived outside the sample country for more than 2 years
#have travelled extensively (more than 6 international experiences of 2 days or longer) 
YEARSABROAD = 2
OVERSEAEXP = 4

get_lived_abroad <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[YEARSABROAD])
})

get_oversea_exp <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[OVERSEAEXP])
})

df.abroad_E <- df.resp_E %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_oversea_experience") %>%
  mutate(lived_abroad = get_lived_abroad(responses)) %>%
  mutate(oversea_exp = get_oversea_exp(responses))

df.lived_abroad_E <- df.abroad_E %>%
  filter(lived_abroad == "Yes")

ppts_lived_abroad_E = unique(df.lived_abroad_E$subject) #29
percent_dropped = length(ppts_lived_abroad_E) / length(unique(df.resp_E$subject))
percent_dropped #0.171875

df.oversea_exp_E <- df.abroad_E %>%
  filter(oversea_exp == "Six or more experiences")

ppts_oversea_exp_E = unique(df.oversea_exp_E$subject) #77
percent_dropped = length(ppts_oversea_exp_E) / length(unique(df.resp_E$subject))
percent_dropped #0.44 # will not use this criterion

df.resp_E <- df.resp_E %>%
  filter(!(subject %in% ppts_non_native_lang_E),
         !(subject %in% ppts_vi_speaker_E), 
         !(subject %in% ppts_zh_speaker_E),
         !(subject %in% ppts_lived_abroad_E))

length(unique(df.resp_E$subject)) #132
```

```{r demog_E explore, include = F}
demog <- c("demog-dropdown", "demog-multi-choice", "demog-free-response", "demog-multi-select")
df.demog_E <- df.resp_E %>%
  filter(trial_type %in% demog) 

AGE = 97 #index for age answer
GENDER = 115 #index for gender answer
split_responses <- function(responses) {
  responses <- as.character(responses)
  response_list <- unlist(strsplit(responses, ',|:'))
  response_list <- response_list[seq(1, length(response_list))]
  response_list <- gsub("}", "", response_list)
  response_list <- gsub("\"", "", response_list)
  return(response_list)
}

get_age <- Vectorize(function(responses) {
  responses <- split_responses(responses)
  if(responses[AGE-1] != "A0") {warnings("cannot find age answer")}
  else{return (responses[AGE])}
})

get_gender <- Vectorize(function(responses) {
  responses <- split_responses(responses)
  if(responses[GENDER-1] != "A1") {warnings("cannot find gender answer")}
  else{return (responses[GENDER])}
})

df.age_gender_E <- df.demog_E %>%
  filter(variable_type == "demog_age_gender_ethnic") %>%
  select(subject, responses) %>%
  mutate(age = as.numeric(get_age(responses))) %>%
  mutate(age = as.numeric(age)) %>%
  mutate(gender = get_gender(responses))

df.age_gender_E_summ <- df.age_gender_E %>%
  summarize(mean_age = mean(age), 
            median_age = median(age), 
            sd_age = sd(age))
```

```{r loading data V explore, include=F}
df.resp_V <- read.csv("../../data/data_V_0530.csv") %>%
  select(-X)

# check for participants who completed the entire experiment. Because the experiment is
# quite long, some participants decide to come back afterwards, so there are a few files
# that are recorded as incomplete. 
df.ppts_finished_V <- df.resp_V %>% 
  group_by(subject) %>%
  summarize(finished = ifelse("demo-final" %in% unique(variable_type), "yes", "no")) %>%
  filter(finished == "yes")

df.resp_V <- df.resp_V %>%
  filter(subject %in% df.ppts_finished_V$subject) 

df.ppts_att_V <- df.resp_V %>%
  filter(stim_type == "attention check") %>%
  mutate(correct_response = strsplit(cue, "Chn ")) %>%
  mutate(correct_response = sapply(correct_response, "[[", 2)) %>%
  mutate(pass_att_check = ifelse(responses == correct_response, 1, 0)) %>%
  group_by(subject) %>%
  summarize(pass_att_check_percent = mean(pass_att_check)) %>%
  filter(pass_att_check_percent >= 0.8)

df.resp_V <- df.resp_V %>%
  filter(subject %in% df.ppts_att_V$subject) #73
```

```{r exclusion V explore, include = F}
#non-native speaker
split_responses_demog <- function(responses) {
  responses <- as.character(responses)
  response_list <- unlist(strsplit(responses, ',|:'))
  response_list <- response_list[seq(1, length(response_list))]
  response_list <- gsub("}", "", response_list)
  response_list <- gsub("\"", "", response_list)
  return(response_list)
}

NATIVE_LANG = 2
get_native_lang <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  if(responses[NATIVE_LANG-1] != "{firstlanguage") 
    {warnings("cannot find native language answer")}
  else
    {return (responses[NATIVE_LANG])}
})

df.ppts_non_native_lang_V <- df.resp_V %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_language") %>%
  mutate(native_speaker = get_native_lang(responses)) %>%
  filter(native_speaker == "Khng")

ppts_non_native_lang_V = unique(df.ppts_non_native_lang_V$subject)
percent_dropped = length(ppts_non_native_lang_V) / length(unique(df.resp_V$subject))
percent_dropped #0

#fluent in English
SPEAKER = 2
SPEAKING = 23
UNDERSTANDING = 46

get_speaker <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[SPEAKER])
})

get_fluency_speaking <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[SPEAKING])
})

get_fluency_understanding <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[UNDERSTANDING])
})

df.lang_en_V <- df.resp_V %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_language_en") %>%
  mutate(en_speaker = get_speaker(responses))
  
df.lang_en_fluency_V <- df.resp_V %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_conditional_language_en_fluency") %>%
  mutate(en_fluency_sp = as.numeric(get_fluency_speaking(responses))) %>%
  mutate(en_fluency_ud = as.numeric(get_fluency_understanding(responses)))

df.lang_en_V <- full_join(df.lang_en_V, 
                          df.lang_en_fluency_V, 
                          by = "subject") %>%
  select(subject, en_speaker, en_fluency_sp, en_fluency_ud) %>%
  filter(en_speaker == "C",
         en_fluency_sp > 4, 
         en_fluency_ud > 4)

ppts_en_speaker_V = unique(df.lang_en_V$subject) #4
percent_dropped = length(ppts_en_speaker_V) / length(unique(df.resp_V$subject))
percent_dropped #0.6861314 # do not use this criterion

df.lang_zh_V <- df.resp_V %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_language_cn") %>%
  mutate(zh_speaker = get_speaker(responses))
  
df.lang_zh_fluency_V <- df.resp_V %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_conditional_language_cn_fluency") %>%
  mutate(zh_fluency_sp = as.numeric(get_fluency_speaking(responses))) %>%
  mutate(zh_fluency_ud = as.numeric(get_fluency_understanding(responses)))

df.lang_zh_V <- full_join(df.lang_zh_V, 
                          df.lang_zh_fluency_V, 
                          by = "subject") %>%
  select(subject, zh_speaker, zh_fluency_sp, zh_fluency_ud) %>%
  filter(zh_speaker == "C",
         zh_fluency_sp > 4, 
         zh_fluency_ud > 4)

ppts_zh_speaker_V = unique(df.lang_zh_V$subject) #4
percent_dropped = length(ppts_zh_speaker_V) / length(unique(df.resp_V$subject))
percent_dropped #0.05839416

#have lived outside the sample country for more than 2 years
#have travelled extensively (more than 6 international experiences of 2 days or longer) 
YEARSABROAD = 2
OVERSEAEXP = 4

get_lived_abroad <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[YEARSABROAD])
})

get_oversea_exp <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[OVERSEAEXP])
})

df.abroad_V <- df.resp_V %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_oversea_experience") %>%
  mutate(lived_abroad = get_lived_abroad(responses)) %>%
  mutate(oversea_exp = get_oversea_exp(responses))

df.lived_abroad_V <- df.abroad_V %>%
  filter(lived_abroad == "C")

ppts_lived_abroad_V = unique(df.lived_abroad_V$subject)
percent_dropped = length(ppts_lived_abroad_V) / length(unique(df.resp_V$subject))
percent_dropped #0.1094891

df.oversea_exp_V <- df.abroad_V %>%
  filter(oversea_exp == "6 ln tr ln")

ppts_oversea_exp_V = unique(df.oversea_exp_V$subject) #77
percent_dropped = length(ppts_oversea_exp_V) / length(unique(df.resp_V$subject))
percent_dropped #0.1094891

df.resp_V <- df.resp_V %>%
  filter(!(subject %in% ppts_non_native_lang_V),
         !(subject %in% ppts_oversea_exp_V), 
         !(subject %in% ppts_zh_speaker_V),
         !(subject %in% ppts_lived_abroad_V))

length(unique(df.resp_V$subject))  #110
```

```{r demog_V explore, include = F}
demog <- c("demog-dropdown", "demog-multi-choice", "demog-free-response", "demog-multi-select")
df.demog_V <- df.resp_V %>%
  filter(trial_type %in% demog)

AGE = 97 #index for age answer
GENDER = 115 #index for gender answer
split_responses <- function(responses) {
  responses <- as.character(responses)
  response_list <- unlist(strsplit(responses, ',|:'))
  response_list <- response_list[seq(1, length(response_list))]
  response_list <- gsub("}", "", response_list)
  response_list <- gsub("\"", "", response_list)
  return(response_list)
}

get_age <- Vectorize(function(responses) {
  responses <- split_responses(responses)
  if(responses[AGE-1] != "A0") {warnings("cannot find age answer")}
  else{return (responses[AGE])}
})

get_gender <- Vectorize(function(responses) {
  responses <- split_responses(responses)
  if(responses[GENDER-1] != "A1") {warnings("cannot find gender answer")}
  else{return (responses[GENDER])}
})

df.age_gender_V <- df.demog_V %>%
  filter(variable_type == "demog_age_gender_ethnic") %>%
  select(subject, responses) %>%
  mutate(age = as.numeric(get_age(responses))) %>%
  mutate(age = as.numeric(age)) %>%
  mutate(gender = get_gender(responses))

df.age_gender_V_summ <- df.age_gender_V %>%
  summarize(mean_age = mean(age), 
            median_age = median(age), 
            sd_age = sd(age))
```

```{r loading data M explore, warning=FALSE, include=F}
df.resp_M <- read.csv("../../data/data_M_0530.csv") %>%
  select(-X)

# check for participants who completed the entire experiment. Because the experiment is
# quite long, some participants decide to come back afterwards, so there are a few files
# that are recorded as incomplete. 
df.ppts_finished_M <- df.resp_M %>% 
  group_by(subject) %>%
  summarize(finished = ifelse("demo-final" %in% unique(variable_type), "yes", "no")) %>%
  filter(finished == "yes")

df.resp_M <- df.resp_M %>%
  filter(subject %in% df.ppts_finished_M$subject) 

df.ppts_att_M <- df.resp_M %>%
  filter(stim_type == "attention check") %>%
  mutate(correct_response = strsplit(cue, "")) %>%
  mutate(correct_response = sapply(correct_response, "[[", 2)) %>%
  mutate(correct_response = str_replace_all(correct_response, "", "")) %>%
  mutate(correct_response = str_replace_all(correct_response, "", "")) %>%
  mutate(pass_att_check = ifelse(responses == correct_response, 1, 0)) %>%
  group_by(subject) %>%
  summarize(pass_att_check_percent = mean(pass_att_check)) %>%
  filter(pass_att_check_percent >= 0.8)

df.resp_M <- df.resp_M %>%
  filter(subject %in% df.ppts_att_M$subject) 
```

```{r exclusion M explore, include = F, warning = F}
#non-native speaker
split_responses_demog <- function(responses) {
  responses <- as.character(responses)
  response_list <- unlist(strsplit(responses, ',|:'))
  response_list <- response_list[seq(1, length(response_list))]
  response_list <- gsub("}", "", response_list)
  response_list <- gsub("\"", "", response_list)
  return(response_list)
}

NATIVE_LANG = 2
get_native_lang <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  if(responses[NATIVE_LANG-1] != "{firstlanguage") 
    {warnings("cannot find native language answer")}
  else
    {return (responses[NATIVE_LANG])}
})

df.ppts_non_native_lang_M <- df.resp_M %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_language") %>%
  mutate(native_speaker = get_native_lang(responses)) %>%
  filter(native_speaker == "")

ppts_non_native_lang_M = unique(df.ppts_non_native_lang_M$subject) #2
percent_dropped = length(ppts_non_native_lang_M) / length(unique(df.resp_M$subject))
percent_dropped #0.01149425

#fluent in English
SPEAKER = 2
SPEAKING = 23
UNDERSTANDING = 46

get_speaker <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[SPEAKER])
})

get_fluency_speaking <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[SPEAKING])
})

get_fluency_understanding <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[UNDERSTANDING])
})

df.lang_en_M <- df.resp_M %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_language_en") %>%
  mutate(en_speaker = get_speaker(responses))
  
df.lang_en_fluency_M <- df.resp_M %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_conditional_language_en_fluency") %>%
  mutate(en_fluency_sp = as.numeric(get_fluency_speaking(responses))) %>%
  mutate(en_fluency_ud = as.numeric(get_fluency_understanding(responses)))

df.lang_en_M <- full_join(df.lang_en_M, 
                          df.lang_en_fluency_M, 
                          by = "subject") %>%
  select(subject, en_speaker, en_fluency_sp, en_fluency_ud) %>%
  filter(en_speaker == "",
         en_fluency_sp > 4, 
         en_fluency_ud > 4)

ppts_en_speaker_M = unique(df.lang_en_M$subject) #50
percent_dropped = length(ppts_en_speaker_M) / length(unique(df.resp_M$subject))
percent_dropped #0.3850575 # will not use this criterion

df.lang_vi_M <- df.resp_M %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_language_vi") %>%
  mutate(vi_speaker = get_speaker(responses))
  
df.lang_vi_fluency_M <- df.resp_M %>%
  filter(variable_type == "demog_conditional_language_vi_fluency") %>%
  mutate(vi_fluency_sp = as.numeric(get_fluency_speaking(responses))) %>%
  mutate(vi_fluency_ud = as.numeric(get_fluency_understanding(responses)))

df.lang_vi_M <- full_join(df.lang_vi_M, 
                          df.lang_vi_fluency_M, 
                          by = "subject") %>%
  select(subject, vi_speaker, vi_fluency_sp, vi_fluency_ud) %>%
  filter(vi_speaker == "",
         vi_fluency_sp > 4, 
         vi_fluency_ud > 4)

ppts_vi_speaker_M = unique(df.lang_vi_M$subject) #50
percent_dropped = length(ppts_vi_speaker_M) / length(unique(df.resp_M$subject))
percent_dropped #0

#have lived outside the sample country for more than 2 years
#have travelled extensively (more than 6 international experiences of 2 days or longer) 
YEARSABROAD = 2
OVERSEAEXP = 4

get_lived_abroad <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[YEARSABROAD])
})

get_oversea_exp <- Vectorize(function(responses) {
  responses <- split_responses_demog(responses)
  return (responses[OVERSEAEXP])
})

df.abroad_M <- df.resp_M %>%
  select(subject, responses, variable_type) %>%
  filter(variable_type == "demog_oversea_experience") %>%
  mutate(lived_abroad = get_lived_abroad(responses)) %>%
  mutate(oversea_exp = get_oversea_exp(responses))

df.lived_abroad_M <- df.abroad_M %>%
  filter(lived_abroad == "")

ppts_lived_abroad_M = unique(df.lived_abroad_M$subject) #23
percent_dropped = length(ppts_lived_abroad_M) / length(unique(df.resp_M$subject))
percent_dropped # 0.1551724

df.oversea_exp_M <- df.abroad_M %>%
  filter(oversea_exp == "")

ppts_oversea_exp_M = unique(df.oversea_exp_M$subject) #0
percent_dropped = length(ppts_oversea_exp_M) / length(unique(df.resp_M$subject))
percent_dropped #0.03448276

df.resp_M <- df.resp_M %>%
  filter(!(subject %in% ppts_non_native_lang_M),
         !(subject %in% ppts_lived_abroad_M),
         !(subject %in% ppts_vi_speaker_M),
         !(subject %in% ppts_oversea_exp_M),)

length(unique(df.resp_M$subject)) #143
```

```{r demog_M explore, include = F}
demog <- c("demog-dropdown", "demog-multi-choice", "demog-free-response", "demog-multi-select")
df.demog_M <- df.resp_M %>%
  filter(trial_type %in% demog) 
#write.csv(data_demog, "data_anon_demog_0201.csv")

AGE = 97 #index for age answer
GENDER = 115 #index for gender answer
split_responses <- function(responses) {
  responses <- as.character(responses)
  response_list <- unlist(strsplit(responses, ',|:'))
  response_list <- response_list[seq(1, length(response_list))]
  response_list <- gsub("}", "", response_list)
  response_list <- gsub("\"", "", response_list)
  return(response_list)
}

get_age <- Vectorize(function(responses) {
  responses <- split_responses(responses)
  if(responses[AGE-1] != "A0") {warnings("cannot find age answer")}
  else{return (responses[AGE])}
})

get_gender <- Vectorize(function(responses) {
  responses <- split_responses(responses)
  if(responses[GENDER-1] != "A1") {warnings("cannot find gender answer")}
  else{return (responses[GENDER])}
})

df.age_gender_M <- df.demog_M %>%
  filter(variable_type == "demog_age_gender_ethnic") %>%
  select(subject, responses) %>%
  mutate(age = as.numeric(get_age(responses))) %>%
  mutate(age = as.numeric(age)) %>%
  mutate(gender = get_gender(responses))

df.age_gender_M_summ <- df.age_gender_M %>%
  summarize(mean_age = mean(age), 
            median_age = median(age), 
            sd_age = sd(age))
```

With the new exclusion criteria, we excluded `r length(unique(df.ppts_finished_E$subject)) - length(unique(df.ppts_att_E$subject))` US participants, `r length(unique(df.ppts_finished_V$subject)) - length(unique(df.ppts_att_V$subject))` VN participants, and `r length(unique(df.ppts_finished_M$subject)) - length(unique(df.ppts_att_M$subject))` CN participants who did not answer more than 2 attention checks correctly. We then applied the 4 criteria that aim to retain only participants who are influenced by one culture: (1) non-native speakers of English and Vietnamese, respectively, (2) fluent in at least one of the other two study languages (Vietnamese for US participants, English for Vietnamese participants and Chinese participants), (3) have lived outside of the test country (US, Vietnam, or China) for more than two years, and (4) have significant international experience (more than 6 international experiences of 2 days or longer.) We did not use a particular criterion for a language if it would exclude 25% or more of any one sample. In this round of exclusion, we excluded `r length(unique(df.ppts_att_E$subject)) - length(unique(df.resp_E$subject))` US, `r length(unique(df.ppts_att_V$subject)) - length(unique(df.resp_V$subject))` VN participants, and `r length(unique(df.ppts_att_M$subject)) - length(unique(df.resp_M$subject))` CN participants. After these exclusions, the US sample included `r length(unique(df.resp_E$subject))` participants (`r df.age_gender_E %>% filter(gender == "Male") %>% count()`M, `r df.age_gender_E %>% filter(gender == "Female") %>% count()`F, `r df.age_gender_E %>% filter(gender == "Non-binary") %>% count()` non-binary, `r df.age_gender_E %>% filter(gender == "Decline to answer") %>% count()` other), with mean age = `r round(df.age_gender_E_summ$mean_age, 2)` (SD = `r round(df.age_gender_E_summ$sd_age, 2)`) and median age = `r df.age_gender_E_summ$median_age`. The VN sample included `r length(unique(df.resp_V$subject))` participants (`r df.age_gender_V %>% filter(gender == "Nam") %>% count()`M, `r df.age_gender_V %>% filter(gender == "N") %>% count()`F), with mean age = `r round(df.age_gender_V_summ$mean_age, 2)` (SD = `r round(df.age_gender_V_summ$sd_age, 2)`) and median age = `r df.age_gender_V_summ$median_age`. The CN sample included `r length(unique(df.resp_M$subject))` participants (`r df.age_gender_M %>% filter(gender == "") %>% count()`M, `r df.age_gender_M %>% filter(gender == "") %>% count()`F), with mean age = `r round(df.age_gender_M_summ$mean_age, 2)` (SD = `r round(df.age_gender_M_summ$sd_age, 2)`) and median age = `r df.age_gender_M_summ$median_age`.

```{r corpus explore, include = F}
df.corpus_E <- read.csv("../../data/corpusE_cos.csv") %>%
  rename(tax_frequency_E = tax.frequency,
         theme_frequency_E = theme.frequency,
         tax_cosine_E = Tax.cosine_dist, 
         theme_cosine_E = Theme.cosine_dist,
         tax_cosine_sim_E = Tax.cosine_sim,
         theme_cosine_sim_E = Theme.cosine_sim,
         tax_match_E = Tax.match,
         theme_match_E = Theme.match, 
         cue_E = Cue)

df.corpus_V <- read.csv("../../data/corpusV_cos.csv") %>%
  rename(tax_frequency_V = tax.frequency,
         theme_frequency_V = theme.frequency,
         tax_cosine_V = Tax.cosine_dist, 
         theme_cosine_V = Theme.cosine_dist,
         tax_cosine_sim_V = Tax.cosine_sim,
         theme_cosine_sim_V = Theme.cosine_sim,
         tax_match_V = Tax.match,
         theme_match_V = Theme.match, 
         cue_V = Cue)

df.corpus_M <- read.csv("../../data/corpusM_cos.csv") %>%
  rename(tax_frequency_M = tax.frequency,
         theme_frequency_M = theme.frequency,
         tax_cosine_M = Tax.cosine_dist, 
         theme_cosine_M = Theme.cosine_dist,
         tax_cosine_sim_M = Tax.cosine_sim,
         theme_cosine_sim_M = Theme.cosine_sim,
         tax_match_M = Tax.match,
         theme_match_M = Theme.match, 
         cue_M = Cue)
```

```{r full corpus explore, M freqs is incorrect, include=F}
df.corpus <- left_join(df.corpus_E, df.corpus_V, by = "Cue_renamed")
df.corpus <- left_join(df.corpus, df.corpus_M, by = "Cue_renamed")

#replacing any 0 raw counts with epsilon
df.corpus <- df.corpus %>%
  mutate(tax_frequency_E = ifelse(tax_frequency_E == 0, 
                                  .Machine$double.eps, tax_frequency_E),
         theme_frequency_E = ifelse(theme_frequency_E == 0, 
                                  .Machine$double.eps, theme_frequency_E),
         tax_frequency_V = ifelse(tax_frequency_V == 0, 
                                  .Machine$double.eps, tax_frequency_V),
         theme_frequency_V = ifelse(theme_frequency_V == 0, 
                                  .Machine$double.eps, theme_frequency_V))

```

```{r corpus - frequency explore, include = F}
#find triads_omit, used whenever analysis uses raw collocates 
df.corpus_E_freq <- df.corpus_E %>%
  select(Cue_renamed, cue_E, tax_match_E, theme_match_E, tax_frequency_E, theme_frequency_E)
corpus_E_omit <- df.corpus_E_freq %>%
  filter(tax_frequency_E == 0 & theme_frequency_E == 0)

df.corpus_V_freq <- df.corpus_V %>%
  select(Cue_renamed, cue_V, tax_match_V, theme_match_V, tax_frequency_V, theme_frequency_V)
corpus_V_omit <- df.corpus_V_freq %>% 
  filter(tax_frequency_V == 0 & theme_frequency_V == 0)

triads_omit <- append(corpus_E_omit$Cue_renamed, corpus_V_omit$Cue_renamed)

df.corpus_freq <- left_join(df.corpus_E_freq, df.corpus_V_freq, by = "Cue_renamed")
```

```{r corpus - cosine explore, include = F}
#mainly for sanity checking and so that there is a parallel df to df.corpus_freq
df.corpus_E_cos <- df.corpus_E %>%
  select(Cue_renamed, cue_E, tax_match_E, theme_match_E, 
         tax_cosine_E, theme_cosine_E,
         tax_cosine_sim_E, theme_cosine_sim_E)

df.corpus_V_cos <- df.corpus_V %>%
  select(Cue_renamed, cue_V, tax_match_V, theme_match_V, tax_cosine_V, theme_cosine_V,
         tax_cosine_sim_V, theme_cosine_sim_V)

df.corpus_M_cos <- df.corpus_M %>%
  select(Cue_renamed, cue_M, tax_match_M, theme_match_M, tax_cosine_M, theme_cosine_M, 
         tax_cosine_sim_M, theme_cosine_sim_M)

df.corpus_cos <- left_join(df.corpus_E_cos, df.corpus_V_cos, by = "Cue_renamed")
df.corpus_cos <- left_join(df.corpus_cos, df.corpus_M_cos, by = "Cue_renamed")
```

```{r getting triads from the 3 languages explore, include = F}
#combine response and corpus data
df.triad_E <- df.resp_E %>%
  filter(stim_type == "triad",
         responses != "NA")
triad_cues_E <- read.csv("../../data/cue_renamed_E.csv")
df.triad_E <- left_join(df.triad_E, triad_cues_E, by = c("cue", "top_opt", "bottom_opt"))
df.triad_E <- inner_join(df.triad_E, df.corpus, by = "Cue_renamed")

df.triad_E <- df.triad_E %>%
  mutate(responses_theme = ifelse(responses == theme_match_E, 1, 0),
         language = "English",
         country = "US") %>%
  select(subject, rt, Cue_renamed, cue, top_opt, bottom_opt, 
         responses, responses_theme, country, language,
         tax_match_E, theme_match_E, tax_match_V, theme_match_V, tax_match_M, theme_match_M,
         tax_frequency_E, theme_frequency_E, tax_frequency_V, theme_frequency_V, tax_frequency_M, theme_frequency_M,
         tax_cosine_E, theme_cosine_E, tax_cosine_V, theme_cosine_V, tax_cosine_M, theme_cosine_M,
         tax_cosine_sim_E, theme_cosine_sim_E, tax_cosine_sim_V, theme_cosine_sim_V, tax_cosine_sim_M, theme_cosine_sim_M)

df.triad_V <- df.resp_V %>%
  filter(stim_type == "triad",
         responses != "NA")
triad_cues_V <- read.csv("../../data/cue_renamed_V.csv")
df.triad_V <- left_join(df.triad_V, triad_cues_V, by = c("cue", "top_opt", "bottom_opt"))
df.triad_V <- inner_join(df.triad_V, df.corpus, by = "Cue_renamed")

df.triad_V <- df.triad_V %>%
  mutate(responses_theme = ifelse(responses == theme_match_V, 1, 0),
         language = "Vietnamese", 
         country = "Vietnam") %>%
  select(subject, rt, Cue_renamed, cue, top_opt, bottom_opt, 
         responses, responses_theme, country, language,
         tax_match_E, theme_match_E, tax_match_V, theme_match_V, tax_match_M, theme_match_M,
         tax_frequency_E, theme_frequency_E, tax_frequency_V, theme_frequency_V, tax_frequency_M, theme_frequency_M,
         tax_cosine_E, theme_cosine_E, tax_cosine_V, theme_cosine_V, tax_cosine_M, theme_cosine_M,
         tax_cosine_sim_E, theme_cosine_sim_E, tax_cosine_sim_V, theme_cosine_sim_V, tax_cosine_sim_M, theme_cosine_sim_M)

df.triad_M <- df.resp_M %>%
  filter(stim_type == "triad",
         responses != "NA")
triad_cues_M <- read.csv("../../data/cue_renamed_M.csv")
df.triad_M <- left_join(df.triad_M, triad_cues_M, by = c("cue", "top_opt", "bottom_opt"))
df.triad_M <- inner_join(df.triad_M, df.corpus, by = "Cue_renamed")

df.triad_M <- df.triad_M %>%
  mutate(responses_theme = ifelse(responses == theme_match_M, 1, 0),
         language = "Mandarin", 
         country = "China") %>%
  select(subject, rt, Cue_renamed, cue, top_opt, bottom_opt, 
         responses, responses_theme, country, language,
         tax_match_E, theme_match_E, tax_match_V, theme_match_V, tax_match_M, theme_match_M,
         tax_frequency_E, theme_frequency_E, tax_frequency_V, theme_frequency_V, tax_frequency_M, theme_frequency_M,
         tax_cosine_E, theme_cosine_E, tax_cosine_V, theme_cosine_V, tax_cosine_M, theme_cosine_M,
         tax_cosine_sim_E, theme_cosine_sim_E, tax_cosine_sim_V, theme_cosine_sim_V, tax_cosine_sim_M, theme_cosine_sim_M)

#calculate proportion for raw frequencies and cosine distance
df <- rbind(df.triad_E, df.triad_V)
df <- rbind(df, df.triad_M) %>%
  mutate(theme_freq_prop_E = theme_frequency_E / (theme_frequency_E + tax_frequency_E),
         theme_freq_prop_V = theme_frequency_V / (theme_frequency_V + tax_frequency_V), 
         theme_freq_prop_M = theme_frequency_M / (theme_frequency_M + tax_frequency_M), 
         theme_cosine_prop_E = theme_cosine_E / (theme_cosine_E + tax_cosine_E),
         theme_cosine_prop_V = theme_cosine_V / (theme_cosine_V + tax_cosine_V), 
         theme_cosine_prop_M = theme_cosine_M / (theme_cosine_M + tax_cosine_M)) %>%
  rename(triad = Cue_renamed)
```

```{r country effect - explore, warning=FALSE, include=FALSE, paged.print=TRUE}
df.country <- df %>%
  group_by(subject, country) %>%
  summarize(theme_resp_percent = mean(responses_theme, na.rm = T))

df.country_sum <- df.country %>%
  group_by(country) %>%
  summarize(mean_theme_resp_percent = mean(theme_resp_percent), 
            sd_theme_resp_percent = sd(theme_resp_percent))

fit.country = glmer(responses_theme ~ country + (1 | subject) + (country | triad), 
                    data = df, 
                    family = "binomial")
summary(fit.country) 
fit.country.anova = Anova(fit.country, type=3)

fit.country_EN_VN = glmer(responses_theme ~ country + (1 | subject) + (country | triad), 
                    data = df %>% filter(country != "China"),
                    family = "binomial")
summary(fit.country_EN_VN) 
```

```{r echo=FALSE, warning=FALSE, fig.cap="Proportion of thematic responses by country, with a less stringent attention check criterion. We did not find any significant differences from the analysis reported above with a more stringent criterion."}

ggplot(df.country,
       mapping = aes(x = country, 
                     y = theme_resp_percent, 
                     color = country)) +
  geom_violin() +
  geom_jitter(height = 0, 
              alpha = 0.3) +  
  stat_summary(fun.data = "mean_cl_boot", 
               geom = "pointrange") + 
  labs(y = "Proportion Thematic Chosen", 
       x = "Country", 
       color = "Country") + 
  scale_color_manual(values=c("#D63230", "#1C77C3", "#F39237"))
```

There is no significant difference in this round of analysis compared to the one reported above (with more stringent attention check criterion). That is, we still observed a significant effect of country on proportion of thematic responses ($\chi^2$(`r fit.country.anova["country", "Df"]`) = `r round(fit.country.anova["country", "Chisq"], 2)`, p < .001), but this effect is driven by only the difference between US and China response ($\beta$ = `r round(fixef(fit.country)["countryUS"], 2)`, p < .001). There is no statistical difference between the Vietnam and China response ($\beta$ = `r round(fixef(fit.country)["countryVietnam"], 2)`, p = `r round(as.data.frame(summary(fit.country)[["coefficients"]])["countryVietnam", "Pr(>|z|)"], 3)`), and the US and Vietnam response ($\beta$ = `r round(fixef(fit.country_EN_VN)["countryVietnam"], 2)`, p = `r round(as.data.frame(summary(fit.country)[["coefficients"]])["countryVietnam", "Pr(>|z|)"], 3)`).

# Discussion
In this paper, we consider whether statistics of the language environment can account for cross-cultural differences in a classic similarity judgment paradigm, as an alternative to the view that members of different cultures vary in their conception of similarity. 

We first tested the generality of a cultural account which holds that people from Western and East Asian cultures tend to conceive of similarity in more taxonomic and thematic ways, respectively, and respond accordingly in categorization tasks such as ours. While we managed to replicate the previously documented contrast between English speakers in the US and Mandarin Chinese speakers from East Asia (mainland China, Taiwan, Hong Kong, and Singapore), we do not extend this contrast to our sample of Vietnamese speakers in Vietnam and English speakers in the US. This finding suggests some limitations on the generality of this cultural account. 

We did find some signatures of language specificity in our analysis, such as the large positive correlation between similarity judgments of each country and the respective corpus statistics, and how each corpus statistics are good predictors for corresponding country's similarity judgments. However, this is potentially due to the high correlation between corpus statistics of English, Vietnamese and Mandarin. We find even stronger evidence for consistency across the three groups, with substantive overlapping predictions across the corpus models, highly similar responding across the experiments, and a correspondingly high fit in cross-language comparisons between models and data.

```{r include=FALSE}
fit.country_no_triad <- glmer(responses_theme ~ country + (1 | subject), 
                              data = df_main_analysis, 
                              family = "binomial")

fit.country = glmer(responses_theme ~ country + (1 | subject) + (country | triad), 
                    data = df_main_analysis, 
                    family = "binomial")
summary(fit.country)

fit.no_triad_compare <- anova(fit.country, fit.country_no_triad, type = 3)
```

There are some suggestions that the current approach can predict triad-specific cross-cultural effects. First of all, an ANOVA model comparison showed that adding a random effect term for varying slope by country and varying intercept by triad to the model produces a significant better fit than the identical model without this random effect term included as a predictor ($\chi^2$(`r fit.no_triad_compare["fit.country", "Df"]`) = `r round(fit.no_triad_compare["fit.country", "Chisq"], 2)`, p < .001)

Anecdotally, we show below some examples of triads that show contrasting difference in the magnitude of difference in thematic responses between countries. As a review, the overall result across all triads showed that there was significant difference between US and China responding, and no significant differences between US and Vietnam or China and Vietnam responding. However, we observed that for the triad "cow-grass-chicken," there were significant differences between US and China, and US and Vietnam responding. There was no significant difference between China and Vietnam responding. For the triad "spoon-sugar-fork," there were significant difference between China and US, and China and Vietnam responding, but no significant difference between US and Vietnam. For the triad "hair-comb-beard," there were no significant differences pairwise across the three cultural contexts. This suggests that there are triad-specific cross-cultural effects in play. Beyond emphasizing the importance of including triad predictors as a random effect, this finding suggests that, firstly, future similar studies need to report triads that are used, as the triads used can affect results (for example, if a study only includes triads where China and US responding are significantly different, it would be more likely to conclude that Chinese and US cultures hold different notions of similarity). Secondly, that future studies can look more deeply into which groups of triads are driving the US-China responding difference. For example, triads belonging to different semantic neighborhoods might be influencing cross-cultural responding in different ways.

```{r include=FALSE}
df.country_item <- df_main_analysis %>%
  filter(triad == "hair")

plot.hair <- ggplot(df.country_item,
       mapping = aes(x = factor(country, levels=c("China", "US", "Vietnam")), 
                     y = responses_theme, 
                     color = factor(country, levels=c("China", "US", "Vietnam")))) +
  geom_jitter(stat = "identity", alpha  = .5) +
  labs(y = "Proportion Thematic Chosen (hair: beard / comb)",  
       x = "Country", 
       color = "Country") + 
  stat_summary(fun.data = "mean_cl_boot", 
               geom = "pointrange") + 
  scale_y_continuous(limits=c(0.0, 1.0), oob = scales::squish) + 
  scale_fill_manual(values=c("#D63230", "#1C77C3", "#F39237")) +  
  scale_color_manual(values=c("#D63230", "#1C77C3", "#F39237"))  + 
  theme(axis.title = element_text(size=rel(0.75)))
```

```{r include=FALSE}
df.country_item <- df_main_analysis %>%
  filter(triad == "spoon2")

plot.spoon2 <- ggplot(df.country_item,
       mapping = aes(x = factor(country, levels=c("China", "US", "Vietnam")), 
                     y = responses_theme, 
                     color = factor(country, levels=c("China", "US", "Vietnam")))) +
  geom_jitter(stat = "identity", alpha  = .5) +
  labs(y = "Proportion Thematic Chosen (spoon: fork / sugar)",  
       x = "Country", 
       color = "Country") + 
  stat_summary(fun.data = "mean_cl_boot", 
               geom = "pointrange") + 
  scale_y_continuous(limits=c(0.0, 1.0), oob = scales::squish) + 
  scale_fill_manual(values=c("#D63230", "#1C77C3", "#F39237")) +  
  scale_color_manual(values=c("#D63230", "#1C77C3", "#F39237")) + 
  theme(legend.position = "none") + 
  theme(axis.title = element_text(size=rel(0.75)))
```

```{r include = FALSE}
#show 1 triad

df.country_item <- df_main_analysis %>%
  filter(triad == "cow2")

df.country_item_summ <- df_main_analysis %>%
  group_by(triad, country) %>%
  summarize(theme_resp_percent = mean(responses_theme, na.rm = T)) %>%
  filter(triad == "cow2")

plot.cow2 <- ggplot(df.country_item,
       mapping = aes(x = factor(country, levels=c("China", "US", "Vietnam")), 
                     y = responses_theme, 
                     color = factor(country, levels=c("China", "US", "Vietnam")))) +
  geom_jitter(stat = "identity", alpha  = .5) +
  labs(y = "Proportion Thematic Chosen (cow: chicken / grass)",  
       x = "Country", 
       color = "Country") + 
  stat_summary(fun.data = "mean_cl_boot", 
               geom = "pointrange") + 
  scale_y_continuous(limits=c(0.0, 1.0), oob = scales::squish) + 
  scale_fill_manual(values=c("#D63230", "#1C77C3", "#F39237")) +  
  scale_color_manual(values=c("#D63230", "#1C77C3", "#F39237")) + 
  theme(legend.position = "none") + 
  theme(axis.title = element_text(size=rel(0.75)))
# 
# +  
#   geom_bar(data = df.country_item_summ, 
#            mapping = aes(x = factor(country, levels=c("China", "US", "Vietnam")), 
#                           y = theme_resp_percent, 
#                          color = factor(country, levels=c("China", "US", "Vietnam"))), 
#            stat='identity', alpha = .3, 
#            fill=c("#D63230", "#1C77C3", "#F39237"))
```

```{r echo=FALSE, warning = FALSE, fig.width=8, fig.cap="Anecdotal evidence of triad-specific effects. Cow-grass-chicken shows significant differences between US-China responding, and between US-Vietnam responding. Spoon-sugar-fork shows only a significant difference between US-China responding. Hair-comb-beard does not show any significant differences in pairwise comparisons across the three countries."}
plot.cow2 + plot.spoon2 + plot.hair + 
    plot_layout(ncol = 3)
```


We also identified some data quality / quantity issues that are an obstacle to modeling similarity in Vietnamese and Mandarin. As stated above, we were not able to find a Mandarin corpus with raw co-occurrences that contains similar magnitude of number of sentences as our English corpus (COCA). Additionally, we could only retrieve fastText word vectors for Vietnamese and Mandarin that are trained on both Common Crawl and Wikipedia. 63% of the articles on Vietnamese Wikipedia and 16% of the Chinese Wikipedia are bot translations from another language (compared to 3% of English Wikipedia). This would affect the quality of the word vectors trained on the Vietnamese and Chinese Wikipedia, potentially making them not reflecting the naturally-occurring lexical co-occurrence in the corresponding language.

Our findings raise additional questions for future work: if not differences in taxonomic vs. thematic responding, then what differences drive the relativity effects previous studies have observed? To what extent are the relativity effects driven by language, and to what extent by culture? @Ji2004 established that culture-aligned differences in this paradigm exist, even when the test language is held constant, concluding that it is culture (independent of the testing language) that led to different grouping styles in their study. Our data provide a cautionary note to this conclusion, suggesting that semantic representations in bilinguals (see @Francis2005 for a review) may have the potential to provide an offline account for cross-context differences in similarity judgments, independent of test language. However, there are still many open questions for this account. How do semantic associations guide categorization? Can they explain taxonomic-thematic differences of the type reported by @Ji2004 and others? Can we provide a more specific computational account than the simple frequency model tested here?

Despite these caveats, our findings here demonstrate the plausibility of an alternative perspective on cross-cultural accounts of language, thought, and similarity in the case of taxonomic and thematic reasoning: that it may be the input to similarity judgments, rather than the evaluative process or the conceptualization of similarity that produces variation in similarity reasoning across cultural and linguistic contexts. We hope this work provides a foundation for further research probing this question. 

[^footnote]:While we discuss cross-cultural variability at the level of countries or larger world areas, these are not cultural monoliths. For convenience, we operationalize culture at the level of country, based on where participants were raised. It is an open question whether performance in our participant populations (of relatively young and well-educated adults) is representative of the broader country. This is especially true for societies with substantial ethnic and cultural variation such as the US. We expect that our data is likely to underestimate variation both within and between the countries we sample from.


\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup

\newpage
# Supplemental Information

hi
```{r echo=TRUE, fig.align="center", fig.cap=c("List of triads used"), fig.show="hold"}
#include_graphics(c("../../data/SI_triads/SI_triads_1.jpg"))
include_graphics(c("../../data/SI_triads/SI_triads_1.jpg",
                   "../../data/SI_triads/SI_triads_2.jpg",
                   "../../data/SI_triads/SI_triads_3.jpg",
                   "../../data/SI_triads/SI_triads_4.jpg",
                   "../../data/SI_triads/SI_triads_5.jpg"))
```
